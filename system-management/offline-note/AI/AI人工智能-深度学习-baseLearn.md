@[TOC](TensorFlow-baseLearn)

# 认识人工智能

人工智能即是将原本需要人工完成的事情都转变成规则自动化完成，包含的领域有人脸识别、自动驾驶、对话机器人、语音识别成文字、翻译等。

机器学习是人工智能的形式之一，深度学习是其子集。两者通过训练和优化模型，以解决分类、回归、聚类、降维等问题。

领域学习方向：

- 机器学习
- 神经网络
- 深度学习
- 自然语言处理
- 计算机视觉
- 知识表示
- 机器人学

# 机器学习

监督式学习：
训练阶段，通过给出答案和数据，让样品训练成模型，模型即包含了所需的规则。
推理阶段，通过对前面给出的模型输入测试数据，得到预测结果，根据正确程度重新进行训练调整。

无监督式学习：
人类自身没有准确的答案，只能让其自主完成训练和矫正。

- **分类**（分类算法）：朴素贝叶斯、决策树、逻辑回归、KNN、SVM、随机森林、AdaBoost、XGBoost。
- **回归**（回归算法）：线性回归、决策树、KNN、LARS、弹性网、随机森林、AdaBoost、XGBoost。
- **聚类**（无监督学习）：K-Means、均值漂移、DBSCAN、GMM、HAC。
- **降维**（特征选择）：PCA、因子分析、决策树、随机森林、变量筛选。

**优化方法**：随机梯度下降（SGD）、Adam、RMSProp 等。

**数据处理**：

- **数据清理**：删除缺失数据、异常值处理、特征选择。
- **编码与规范化**：标签编码、独热编码、最小-最大标准化、均值标准化、特征缩放。
- **特征工程**：变量转换、主成分分析（PCA）、特征构造。
- **数据拆分**：训练集、验证集、测试集、交叉验证。

**常见库**：Scikit-learn、Spark MLlib、CARAT、randomForest、Java-ML、RapidMiner、Weka。

# 神经网络

通过模仿动物大脑的神经元结构构建的神经网络，以此结构执行推断直到最终得出结论。
神经元里保留有各种数据状态的记忆，通过分配不同的权重来构建出有层次、有深度的神经网络。

没有神经网络之前机械学习会使用例如朴素贝叶斯算法等统计概率学公式来推算结果。

# 深度学习

基于深度神经网络（DNN），通过**反向传播**优化权重。  
通过机器学习构建更深度更多层次的神经网络，从而让原有的模型更加精准，能根据具体细节纠正，即称为深度学习。
深度学习需要更强大的算力/硬件才能达成，因此过去 30 年发展不明显，直到近些年才被重视和发展起来。
深度学习算法有 CNN、RNN、Transformer 等，前两者主要是用于图像视频领域，后者用于 LLM、NLP 为主，目前因为 ChatGPT、Deepseek 等大语言模型崛起，所以 Transformer 变成最常见的。

- **激活函数**：ReLU、Sigmoid、Tanh。
- **神经网络拓扑**：前馈网络、快捷连接、循环神经网络（RNN）。
- **优化器**：SGD、Adam、RMSProp。
- **常见网络结构**：
  - **卷积神经网络（CNN）**：图像分类、目标检测、图像分割。
  - **递归神经网络（RNN）、LSTM**：自然语言处理（NLP）、时间序列分析。
  - **Transformer、注意力机制**：机器翻译、文本生成。

**非神经网络方法**：

- **随机森林（RDF）**：分类、回归。
- **XGBoost**：梯度提升树（GBT），增强决策树。

**深度学习框架**：TensorFlow、Keras、PyTorch、MXNet、Deeplearning4j、ONNX、TensorRT。

### 机器学习 vs 深度学习

- **计算资源**：机器学习可在 CPU 上运行，深度学习通常需要 GPU/TPU。
- **训练速度**：机器学习更快，深度学习需更长训练时间。
- **应用场景**：
  - 机器学习适用于小数据集、结构化数据。
  - 深度学习适用于自然语言处理、计算机视觉、药物研发等复杂任务。

# 常见的人工智能库

- Pytorch 提供给 Python 使用，是目前最流行的深度学习库，包含各种预训练模型
- TensorFlow，主要提供给 Javascript 使用，简化大部分操作，适合新手练习和快速用于 web
- TensorRT，一款高性能深度学习推理 SDK，提供给 Python 使用

[更多学习路线](https://blog.csdn.net/cfl927096306/article/details/123811274)

# TensorFlow 能做什么

通过部分已经预训练好的模型，配合摄像头、麦克风、陀螺仪、鼠标等完成智能的手势识别、动作识别等。
虽然服务器也能完成，但把部分工作移到客户端，减少网络延迟，减轻服务器压力，而且可以针对个人进行特化训练。

# TensorFlow 使用环境

- 浏览器端 js，毫无疑问浏览器端通过 js 直接调用 TensorFlow.js 是最能发挥上述优势的地方。
- 服务端端 Nodejs，在 nodejs 调用能更好地利用服务器强大的 GPU，并且可以配合[调用 Python](https://blog.csdn.net/qq_30386941/article/details/126819067)
  已有的人工智能库来使用。
- 桌面/服务端调用 Python，Python 本身有大量科学计算与人工智能相关的第三方库，几乎所有算法工程师都会使用相关技能。

# 训练步骤

## 传统训练方式

- 获取训练数据集合，固定少量数据属于硬编码，一般是使用大数据筛选
- 将数据转换成张量
- 创建模型
- 悬链使其契合数据集
- 使用训练好的模型进行预测
- 最终得到线性回归模型或分类模型

## 神经网络训练方式

### 卷积 CNN

- 将图像转换成像素点对应的矩阵向量
- 使用卷积核对图像进行特征提取
- 使用激活函数进行非线性处理
- 重复前两个步骤 N 次来优化结果
- 使用池化来进一步提取各个部分的最佳特征
- 全连接以上，完成前向传播（这里开始和 Transformer 一致）
- 归一化变成概率得出初始模型
- 对预测概率和正确结果进行梯度计算，使用梯度下降算法进行反向传播优化模型，并重复这个行为 N 次来优化模型

### 注意力 Transformer

- 将信息转换成对应的矩阵向量，这个信息一般是用户输入的问题
- 使用 Tokenization 分割词组得到 tokens，并添加位置信息
- 用预训练好的 Query、Key 高维向量矩阵来计算获得每个 token 的 Q&K
- 按位置根据后一个 token 的 Q 关联前面所有 tokens 的 K，据此计算出每个 token 可能的 Value，获得 token-Q-K-V，这就是“注意力”
- 对前两个步骤使用不同的预训练矩阵进行并行计算，从而产生不同的结果，称为“多头注意力”
- 重复多头注意力里的步骤 N 次来优化结果
- 全连接以上，完成前向传播（这里开始和 CNN 一致）
- 归一化变成概率得出初始模型
- 对预测概率和正确结果进行梯度计算，使用梯度下降算法进行反向传播优化模型，并重复这个行为 N 次来优化模型

# 职位

从深到浅，从底层到应用：
* IT运维工程师，CPU/GPU/存储/宽带/内存/系统硬件选型、基础设施维护
* 模型算法工程师，研发基础、数据预处理、模型搭建、训练与部署
* AI模型开发工程师，微调模型、RAG、FSL、模型评估、模型部署
* AI应用开发工程师，应用开发、系统集成、用户体验优化、产品实现